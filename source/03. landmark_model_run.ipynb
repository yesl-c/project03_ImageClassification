{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "augmentation.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTvqxvnxCX-H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "982d9a34-db14-4a7f-ba06-bbd584018657"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JR6q-x2wCMj2",
        "colab_type": "text"
      },
      "source": [
        "### 00. 라이브러리 호출"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqnRVLRaCrs6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os,glob\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from sklearn import model_selection\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enJqAtIBCyWY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c27d169e-82e5-4b10-d3cc-7cee6275737a"
      },
      "source": [
        "import sys, os\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras.utils import np_utils\n",
        "from keras.layers import LeakyReLU\n",
        "import numpy as np"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BijsN0mkCdF4",
        "colab_type": "text"
      },
      "source": [
        "### 01. 경로 지정 및 기타"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFNeoh2ZDVqZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "root_dir = '/content/gdrive/My Drive/image_project/landmark/'\n",
        "\n",
        "categories = [\n",
        "\"Eiffel Tower\"\n",
        ",\"Cristo Redentor\"\n",
        ",\"Triumphal Arch\"\n",
        ",\"Wànlĭ Chángchéng\"\n",
        ",\"Taj Mahal\"\n",
        ",\"Sungnyemun Gate\"\n",
        ",\"Moai\"\n",
        ",\"Seokguram buddha\"\n",
        ",\"Golden Gate\"\n",
        ",\"Statue of Liberty\"\n",
        ",\"Torre di Pisa\"\n",
        ",\"Colosseum\"\n",
        ",\"Santiago Bernabéu\"\n",
        ",\"Sphinx\"\n",
        ",\"Burj Khalifa\"\n",
        ",\"London Eye\"\n",
        ",\"London Tower Bridge\" \n",
        "] \n",
        "\n",
        "nb_classes = len(categories)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9qN0mrNFshX",
        "colab_type": "text"
      },
      "source": [
        "### 02. 데이터 로딩 함수 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKljUgC1C2kC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_dataset():\n",
        "    x_train, x_test, y_train, y_test = np.load(root_dir+'landmark_augmentation.npy', allow_pickle=True)\n",
        "                                               \n",
        "    print(x_train.shape, y_train.shape)\n",
        "    \n",
        "    x_train = x_train.astype('float') / 256\n",
        "    x_test = x_test.astype('float') / 256\n",
        "    \n",
        "    y_train = np_utils.to_categorical(y_train, nb_classes)   # one-hot-encoding\n",
        "    y_test = np_utils.to_categorical(y_test, nb_classes)\n",
        "    \n",
        "    return x_train, x_test, y_train, y_test"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZHca9OLGFZY",
        "colab_type": "text"
      },
      "source": [
        "### 03-1. 모델 구성 함수 생성\n",
        "* 검증방법 : 정확도"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUN0w4NTDsrx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(in_shape):\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Convolution2D(32,3,3, border_mode='Same', input_shape=in_shape))\n",
        "    model.add(LeakyReLU(alpha=0.01))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.25))\n",
        "    \n",
        "    model.add(Convolution2D(64,3,3, border_mode='Same'))\n",
        "    model.add(LeakyReLU(alpha=0.01))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.25))\n",
        "    \n",
        "    model.add(Convolution2D(128,3,3, border_mode='Same'))\n",
        "    model.add(LeakyReLU(alpha=0.01))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.25))\n",
        "    \n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512))\n",
        "    model.add(LeakyReLU(alpha=0.01))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(nb_classes))\n",
        "    model.add(Activation('softmax'))\n",
        "    \n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61RusbpXFyPm",
        "colab_type": "text"
      },
      "source": [
        "### 03-2. 모델 구성 함수 생성\n",
        "* 검증방법 : 상위 3개 중 정답이 있으면 맞춘 것으로"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnNKM0MdDhoJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import metrics \n",
        "import tensorflow as tf\n",
        "    \n",
        "def build_model(in_shape):\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Convolution2D(32,3,3, border_mode='Same', input_shape=in_shape))\n",
        "    model.add(LeakyReLU(alpha=0.01))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.25))\n",
        "    \n",
        "    model.add(Convolution2D(64,3,3, border_mode='Same'))\n",
        "    model.add(LeakyReLU(alpha=0.01))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.25))\n",
        "    \n",
        "    model.add(Convolution2D(128,3,3, border_mode='Same'))\n",
        "    model.add(LeakyReLU(alpha=0.01))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.25))\n",
        "    \n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512))\n",
        "    model.add(LeakyReLU(alpha=0.01))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(nb_classes))\n",
        "    model.add(Activation('softmax'))\n",
        "    \n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=[tf.keras.metrics.TopKCategoricalAccuracy(k=3, \n",
        "                                                                    name='top_k_categorical_accuracy', \n",
        "                                                                    dtype=None)])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AgGnUbBGYa3",
        "colab_type": "text"
      },
      "source": [
        "### 04. 모델 학습 함수 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fb3h97KqEThX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from keras.callbacks import EarlyStopping\n",
        "#epochs=300\n",
        "#early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
        "\n",
        "def model_train(x, y):\n",
        "    print(x.shape[1:])\n",
        "    model = build_model(x.shape[1:])\n",
        "    model.fit(x, y, batch_size=128, epochs=100)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1A-n3BmPGhJm",
        "colab_type": "text"
      },
      "source": [
        "### 05. 모델 평가 함수 생성\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgzIVoceEVGi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_eval(model, x, y):\n",
        "    score = model.evaluate(x, y)\n",
        "    print('loss = ', score[0])\n",
        "    print('accuracy = ', score[1])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgMu4sRKG7W-",
        "colab_type": "text"
      },
      "source": [
        "### 06. 모델 생성, 학습, 평가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjoOTyJIEWp4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "cd6b9955-1654-4035-b62c-a2c430d12ac1"
      },
      "source": [
        "# 데이터 불러오기\n",
        "x_train, x_test, y_train, y_test = load_dataset()\n",
        "\n",
        "print(x_train.shape, y_train.shape, x_test.shape,  y_test.shape)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(49130, 128, 128, 3) (49130,)\n",
            "(49130, 128, 128, 3) (49130, 17) (16377, 128, 128, 3) (16377, 17)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zll9jOQPHw6U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "\n",
        "# 모델 학습\n",
        "model = model_train(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqnhwwMoEYwx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 학습이 완료된 모델을 저장\n",
        "\n",
        "model.save('/content/gdrive/My Drive/image_project/landmark/landmark_model23.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAq3p6g5aaGF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d22ec391-7d8e-41d9-f9ac-005e30dcf0b3"
      },
      "source": [
        "# 테스트 데이터 로딩\n",
        "def load_test_dataset():\n",
        "    x_train, x_test, y_train, y_test = np.load('/content/gdrive/My Drive/image_project/landmark/landmark_test.npy', allow_pickle=True)\n",
        "                                               \n",
        "    x_test = x_train / 256\n",
        "    xxx = x_test / 256\n",
        "    \n",
        "    y_test = np_utils.to_categorical(y_train, nb_classes)   # one-hot-encoding\n",
        "    yyy = np_utils.to_categorical(y_test, nb_classes)\n",
        "    \n",
        "    return x_test, xxx, y_test, yyy\n",
        "\n",
        "x_test, xxx, y_test, yyy = load_test_dataset()\n",
        "print(x_test.shape, y_test.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(152, 128, 128, 3) (152, 17)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZ7c-tQRDjr9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 저장된 모델 불러오기\n",
        "\n",
        "from tensorflow.python.keras.models import load_model\n",
        "model = load_model('/content/gdrive/My Drive/image_project/landmark/landmark_model23.h5')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjTddEyPEak4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "9065ce26-0c8e-4915-8be6-d1cb49b30d27"
      },
      "source": [
        "# 모델 평가\n",
        "model_eval(model, x_test, y_test)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 0s 35ms/step - loss: 2.1555 - accuracy: 0.8553\n",
            "loss =  2.1555373668670654\n",
            "accuracy =  0.8552631735801697\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}